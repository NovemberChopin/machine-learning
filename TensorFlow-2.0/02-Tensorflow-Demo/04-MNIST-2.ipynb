{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手写数字识别\n",
    "**自动计算准确度（metrics）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers, optimizers, datasets, Sequential, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n"
     ]
    }
   ],
   "source": [
    "(xs, ys),_ = datasets.mnist.load_data()\n",
    "print('datasets:', xs.shape, ys.shape, xs.min(), xs.max())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "xs = tf.convert_to_tensor(xs, dtype=tf.float32) / 255.\n",
    "db = tf.data.Dataset.from_tensor_slices((xs,ys))\n",
    "db = db.batch(batch_size).repeat(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(256, activation='relu'), \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "model.build(input_shape=(4, 28*28))\n",
    "model.summary()\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "acc_meter = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 0.0978606790304184 acc: 0.9759489\n",
      "2000 loss: 0.09753087908029556 acc: 0.96928126\n",
      "4000 loss: 0.0901997983455658 acc: 0.9710938\n",
      "6000 loss: 0.08087755739688873 acc: 0.97223437\n",
      "8000 loss: 0.09405967593193054 acc: 0.97353125\n",
      "10000 loss: 0.11057624220848083 acc: 0.9750469\n",
      "12000 loss: 0.046288274228572845 acc: 0.97589064\n",
      "14000 loss: 0.03741767257452011 acc: 0.9768906\n",
      "16000 loss: 0.07959193736314774 acc: 0.978\n",
      "18000 loss: 0.060375623404979706 acc: 0.97915626\n",
      "20000 loss: 0.056397806853055954 acc: 0.9796719\n",
      "22000 loss: 0.04052315279841423 acc: 0.9808281\n",
      "24000 loss: 0.07147417962551117 acc: 0.98164064\n",
      "26000 loss: 0.053170979022979736 acc: 0.98240626\n",
      "28000 loss: 0.06844788044691086 acc: 0.9832031\n",
      "30000 loss: 0.03784005716443062 acc: 0.98428124\n",
      "32000 loss: 0.050008852034807205 acc: 0.9846875\n",
      "34000 loss: 0.04482151195406914 acc: 0.9852656\n",
      "36000 loss: 0.047730326652526855 acc: 0.98592186\n",
      "38000 loss: 0.04797711968421936 acc: 0.9863125\n",
      "40000 loss: 0.08105066418647766 acc: 0.98675\n",
      "42000 loss: 0.021308720111846924 acc: 0.9870625\n",
      "44000 loss: 0.021351652219891548 acc: 0.98739064\n",
      "46000 loss: 0.05029582232236862 acc: 0.98759377\n",
      "48000 loss: 0.02949581667780876 acc: 0.98814064\n",
      "50000 loss: 0.03941215202212334 acc: 0.9882344\n",
      "52000 loss: 0.023897267878055573 acc: 0.98859376\n",
      "54000 loss: 0.04697003588080406 acc: 0.98873436\n",
      "56000 loss: 0.04267502203583717 acc: 0.9891094\n"
     ]
    }
   ],
   "source": [
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 打平操作，[b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # Step1. 得到模型输出output [b, 784] => [b, 10]\n",
    "        out = model(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        # 计算差的平方和，[b, 10]\n",
    "        loss = tf.square(out-y_onehot)\n",
    "        # 计算每个样本的平均误差，[b]\n",
    "        loss = tf.reduce_sum(loss) / x.shape[0]\n",
    "\n",
    "\n",
    "    acc_meter.update_state(tf.argmax(out, axis=1), y)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 2000==0:\n",
    "\n",
    "        print(step, 'loss:', float(loss), 'acc:', acc_meter.result().numpy())\n",
    "        acc_meter.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
