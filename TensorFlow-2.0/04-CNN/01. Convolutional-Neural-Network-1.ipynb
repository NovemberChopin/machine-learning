{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, datasets, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 自定义权值实现\n",
    "\n",
    "**在 tensorflow 中：**\n",
    "- $C_{in} = 输入通道数 = 卷积核通道数$\n",
    "- $C_{out} = 卷积核数 = 输出通道数$\n",
    "$$X:[b, h, w, C_{in}],W:[k, k, C_{in}, C_{out}]$$\n",
    "$$\\Downarrow$$\n",
    "$$O:[b, h', w', C_{out}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([2, 5, 5, 3]) # 输入，5*5，3 通道\n",
    "w = tf.random.normal([3, 3, 3, 4]) # 4 个 3*3 大小的卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置步长为 1， padding 为 0\n",
    "# padding 参数的设置格式为: padding=[[0,0],[上,下],[左,右],[0,0]] \n",
    "out = tf.nn.conv2d(x, w, strides=1, padding=[[0, 0], [0, 0], [0, 0], [0, 0]])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding 都为 1\n",
    "out = tf.nn.conv2d(x, w, strides=1, padding=[[0, 0], [1, 1], [1, 1], [0, 0]])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 步长为,padding 设置为输出、输入同大小 \n",
    "# 需要注意的是, padding=same 只有在 strides=1 时才是同大小 \n",
    "out = tf.nn.conv2d(x, w, strides=1, padding='SAME')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2, 2, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当𝑠 > 1 时，设置 padding='SAME'将使得输出高、宽将成 1/s 倍的减少\n",
    "# 高宽先 padding 成可以整除 3 的最小整数 6，然后 6 按 3 倍减少，得到 2x2\n",
    "out = tf.nn.conv2d(x, w, strides=3, padding='SAME')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.conv2D 没有实现偏置向量计算， 所以需要手动添加 偏置 bias\n",
    "b = tf.zeros([4])\n",
    "out = out + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 卷积层类\n",
    "\n",
    "- 在 `TensorFlow` 中，`API` 的命名有 一定的规律，首字母大写的对象一般表示类，全部小写的一般表示函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积核宽高相等时\n",
    "# 创建 4 个 3 × 3大小的卷积核的卷积层，步长为 1， padding 方案为'SAME'\n",
    "layer = layers.Conv2D(4, kernel_size=3, strides=1, padding='SAME')\n",
    "# 卷积核宽高不等时\n",
    "layer = layers.Conv2D(4, kernel_size=(3, 4), strides=(1, 2), padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Conv2D(4, kernel_size=3, strides=1, padding='SAME')\n",
    "out = layer(x) # 前向计算\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回 W 和 b 的列表\n",
    "# layer.trainable_variables\n",
    "# layer.kernel # layer.weights\n",
    "# layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LeNet-5 实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            multiple                  60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  48120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Conv2D(6, kernel_size=3, strides=1), # 6 个 3x3 的卷积核\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2), # 宽高各减半的池化层\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(16, kernel_size=3, strides=1), # 第二个卷积层, 16 个 3x3 卷积核 \n",
    "    layers.MaxPooling2D(pool_size=2, strides=2), # 宽高各减半的池化层\n",
    "    layers.ReLU(),\n",
    "    layers.Flatten(), # 打平层，方便全连接层处理\n",
    "    \n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "# build 一次网络模型，给输入 X 的形状，其中 4 为随意给的 batchsz \n",
    "network.build(input_shape=(4, 28, 28, 1))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 插入通道维度 => [b, 28, 28, 1]\n",
    "X_train = tf.expand_dims(X_train, axis=3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses:  tf.Tensor(56.36883, shape=(), dtype=float32)\n",
      "losses:  tf.Tensor(372.36215, shape=(), dtype=float32)\n",
      "losses:  tf.Tensor(13.492762, shape=(), dtype=float32)\n",
      "losses:  tf.Tensor(2.3343742, shape=(), dtype=float32)\n",
      "losses:  tf.Tensor(2.3213124, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 通过设置 from_logits=True 标志位将 softmax 激活函数实现在损失函数中\n",
    "# 创建损失函数的类，在实际计算时直接调用类实例即可\n",
    "criteon = losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "\n",
    "for epoch in range(5):\n",
    "    # 构建梯度记录环境\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 前向计算，获得10类别的预测分布，[b, 784] => [b, 10]\n",
    "        out = network(X_train)\n",
    "        # 真实标签one-hot编码，[b] => [b, 10]\n",
    "        y_train_onehot = tf.one_hot(y_train, depth=10)\n",
    "        # 计算交叉熵损失函数，标量\n",
    "        loss = criteon(y_train_onehot, out)\n",
    "    \n",
    "    print(\"losses: \", loss)\n",
    "    # 自动计算梯度\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    # 自动更新参数\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tf.expand_dims(X_test, axis=3)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = network(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1077, shape=(10,), dtype=float32, numpy=\n",
       "array([-0.00110437,  0.00995757, -0.01960377, -0.00108513, -0.00507852,\n",
       "        0.00272152,  0.00353631, -0.00891392,  0.00169442,  0.00873554],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型输出没有经过 softmax\n",
    "y_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = tf.argmax(y_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1087, shape=(100,), dtype=int64, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 9, 1, 1, 3, 1, 1, 1, 1, 1,\n",
       "       1, 0, 9, 1, 1, 1, 1, 1, 3, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 9, 1, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 10])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict2 = network(X_test)\n",
    "y_predict2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
