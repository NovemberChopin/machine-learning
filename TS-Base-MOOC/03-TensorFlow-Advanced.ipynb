{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 进阶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **拼接（Concatenate）：**不会产生新的维度\n",
    "- **条件：**非合并维度的长度必须一致\n",
    "      - tf.concat(tensors, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 35, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4,35,8]) # 模拟成绩册 A \n",
    "b = tf.random.normal([6,35,8]) # 模拟成绩册 B \n",
    "c = tf.concat([a, b], axis=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 35, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([10,35,4]) \n",
    "b = tf.random.normal([10,35,4]) \n",
    "c = tf.concat([a, b], axis=2)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **堆叠（Stack）：**会产生新的维度\n",
    "- **条件：**所有合并的张量 shape 完全一致才可合 并\n",
    "      - tf.stack(tensors, axis)\n",
    "- axis 的用法与 tf.expand_dims 的一致，\n",
    "- 当axis ≥ 0时，在 axis 之前插入\n",
    "- 当axis < 0时， 在 axis 之后插入新维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 35, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([35,8]) \n",
    "b = tf.random.normal([35,8]) \n",
    "c = tf.stack([a,b],axis=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([35, 8, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.stack([a, b], axis=-1) # 在末尾插入维度\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 分割\n",
    "\n",
    "-  tf.split(x, axis, num_or_size_splits)\n",
    "    - x：待分割张量 \n",
    "    - axis：分割的维度索引号 \n",
    "    - num_or_size_splits：切割方案\n",
    "        - 单个数值：表示切割为多少份\n",
    "        - List：表示每份的长度\n",
    "    \n",
    "- 如果希望在某个维度上全部按长度为 1 的方式分割，可以使用\n",
    "$$tf.unstack(x, axis)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([10, 35, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tf.split(x, axis=0, num_or_size_splits=10)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 35, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape # 查看切割后的第一份的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tf.split(x, axis=0, num_or_size_splits=[4, 3, 2, 1])\n",
    "len(result) # 一共有四分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 35, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape # 查看第一份的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 35, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tf.unstack(x, axis=0)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([35, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**可以看出，经过unstack分割后，被分割的维度消失**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/1txQydJt/screenshot-18.png)\n",
    "$$||x||_\\infty = max_i(|x_i|)$$\n",
    "\n",
    "    -  tf.norm(x, ord)\n",
    "    - 参数 ord 指定为 1,2 时计算 L1, L2 范数，\n",
    "    - 指定为 np.inf 时计算∞ −范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones([2,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=143, shape=(), dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(x,ord=1) # 计算 L1 范数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=148, shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.norm(x,ord=2) # 计算 L2 范数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=152, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tf.norm(x,ord=np.inf) # 计算∞范数 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. 最大最小值、均值、和 ...\n",
    "\n",
    "    - tf.reduce_max(x, axis)\n",
    "    - tf.reduce_min(x, axis)\n",
    "    - tf.reduce_mean(x, axis)\n",
    "    - tf.reduce_sum(x, axis)\n",
    "    - tf.reduce_all(x, axis)\n",
    "    - tf.reduce_any(x, axis)\n",
    "    - tf.reduce_prod(x, axis) # 所有元素相乘\n",
    "    - tf.argmax(x, axis)\n",
    "    - tf.argmin(x, axis)\n",
    "    - tf.nn.softmax(out, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([4,10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=168, shape=(4,), dtype=float32, numpy=array([1.7212703, 0.5936285, 0.7765979, 1.2436333], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=162, shape=(), dtype=float32, numpy=1.7212703>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=195, shape=(), dtype=float32, numpy=0.9578208>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在求解误差函数时，通过 TensorFlow 的 MSE 误差函数可以求得每个样本的误差，\n",
    "# 需 要计算样本的平均误差，\n",
    "# 此时可以通过 tf.reduce_mean 在样本数维度上计算均值： \n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "out = tf.random.normal([4,10]) # 网络预测输出 \n",
    "y = tf.constant([1,2,2,0]) # 真实标签 \n",
    "y = tf.one_hot(y,depth=10) # one-hot 编码 \n",
    "loss = keras.losses.mse(y,out) # 计算每个样本的误差 \n",
    "loss = tf.reduce_mean(loss) # 平均误差 \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=209, shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.46641362, -0.23711807,  0.14403515,  0.7536303 ,  0.7507019 ,\n",
       "        -0.26875448,  0.28073084,  2.4310565 , -0.72774553,  0.76742625],\n",
       "       [-0.6579095 ,  0.29487368,  1.276915  , -0.19374578, -0.10336271,\n",
       "        -0.8431471 ,  1.0199311 ,  0.83449227,  0.42395133, -0.2841842 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.random.normal([2, 10])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=210, shape=(2, 10), dtype=float32, numpy=\n",
       "array([[0.06676771, 0.03303898, 0.04836813, 0.08898219, 0.08872201,\n",
       "        0.0320101 , 0.05545305, 0.4762117 , 0.02022785, 0.0902183 ],\n",
       "       [0.0346218 , 0.08977143, 0.23968078, 0.05507232, 0.06028181,\n",
       "        0.02876749, 0.18536448, 0.15398963, 0.10213999, 0.05031025]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.nn.softmax(out, axis=1) # 使用 softmax 将其转化为概率值\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=212, shape=(2,), dtype=float32, numpy=array([1.        , 0.99999994], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(out, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 张量比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出样本\n",
    "out = tf.random.normal([5, 10])\n",
    "out = tf.nn.softmax(out, axis=1)\n",
    "predict = tf.argmax(out, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=239, shape=(5,), dtype=int64, numpy=array([5, 2, 5, 1, 9], dtype=int64)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真实样本\n",
    "y = tf.random.uniform([5],dtype=tf.int64,maxval=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.equal(a, b)\n",
    "- 返回布尔型结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看预测样本是否正确，使用 tf.equal(a, b) 函数可以比较\n",
    "out = tf.equal(predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=244, shape=(5,), dtype=bool, numpy=array([False, False, False,  True, False])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=247, shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.cast(out, dtype=tf.int32) # 布尔型转 int 型 \n",
    "correct = tf.reduce_sum(out) #  # 统计 True 的个数 \n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/j2m4LBkW/screenshot-19.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
