{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8rWm4A.png](https://s1.ax1x.com/2020/03/19/8rWm4A.png)\n",
    "\n",
    "- SVM 要最大化 margin\n",
    "- 解决的是**线性可分**问题（Hard Margin SVM）\n",
    "- 线性不可分问题（Soft Margin SVM）\n",
    "\n",
    "- margin = 2d\n",
    "- 所以 SVM 要最大化 d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hard Margin 推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点到直线的距离：\n",
    "$(x, y) 到 Ax + By + C = 0 的距离：$\n",
    "$$\\frac{|Ax + By + C|}{\\sqrt{A^2 + B^2}}$$\n",
    "\n",
    "- $\\theta$ 有 n+1 个元素，$x_b$ 是增加一列，全为 1. 即 m * (n+1) 的矩阵\n",
    "\n",
    "- 拓展到 n 维空间 $\\theta^Tx_b=0 \\Rightarrow w^Tx + b = 0$\n",
    "\n",
    "- 点到`n`维的距离：\n",
    "$$\\Downarrow$$\n",
    "$$\\frac{|w^T + b|}{||w||} 其中 ||w|| = \\sqrt{w_1^2+w_2^2+...+w_n^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8rWeNd.png](https://s1.ax1x.com/2020/03/19/8rWeNd.png)\n",
    "\n",
    "- 所有公式都用 $w_d 和 b_d$来表示，所以我们就把$w_d 和 b_d 写成 w 和 b$\n",
    "![8rWZAH.png](https://s1.ax1x.com/2020/03/19/8rWZAH.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **用一个式子表示为：**\n",
    "$$y^{(i)}(w^Tx^{(i)} + b) >= 1$$\n",
    "- 对于任意支撑向量 x：\n",
    "$$max\\frac{|w^Tx + b|}{||w||} \\Rightarrow max\\frac{1}{||w||} \\Rightarrow min||w||$$\n",
    "- 为了方便求导，通常我们**最小化**\n",
    "$$min\\frac{1}{2}{||w||}^2$$\n",
    "- SVM 是有条件的最优化问题\n",
    "- 在条件 $y^{(i)}(w^Tx^{(i)} + b) >= 1$ 下求 $min\\frac{1}{2}{||w||}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Soft Margin 推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8rWABD.png](https://s1.ax1x.com/2020/03/19/8rWABD.png)\n",
    "\n",
    "- 如图所示，对于此时的分类，决策边界极大的收到了右下方一个蓝色点的影响\n",
    "- 虽然此时决策边界可以完全正确的分类，但是泛化能力会比较弱\n",
    "- 有可能哪一个蓝色点是噪音，或者是一个极度偏斜的点\n",
    "- 那么显然，当前分类是有问题的\n",
    "- 又或者，当前数据点，没有任何一条直线可以分为两部分\n",
    "- 即允许我们的分类犯一些错误，可以获得更好的泛化能力\n",
    "- 此时就要用到 Soft Margin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们可以在 Hard Margin 的条件后减去一个 $\\zeta$:\n",
    "$$y^{(i)}(w^Tx^{(i)} + b) >= 1 - \\zeta_i  (\\zeta_i >= 0)$$\n",
    "- 注意：每一个点都有对应的 $\\zeta$\n",
    "- 此时最小化的式子为：\n",
    "$$min\\frac{1}{2}{||w||}^2 + \\sum_{i=1}^m\\zeta_i$$\n",
    "- 我们可以加一个超参数 C，来调节比重：\n",
    "$$min\\frac{1}{2}{||w||}^2 + C\\sum_{i=1}^m\\zeta_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **C 越大，容错空间越小**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8rxY90.png](https://s1.ax1x.com/2020/03/19/8rxY90.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
